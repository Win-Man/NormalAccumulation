# 第 1 章 MySQL 体系结构和存储引擎

## 1.1 定义数据库和实例

Linux 下通过命令 `ps -ef | grep mysqld` 查看 MySQL 实例进程是否启动。

通过 `mysql --help | grep my.cnf` 查看 MySQL 数据库实例启动时，会在哪些位置查找配置文件。（按顺序读取，以最后一个文件的配置为准）

在 `mysql> SHOW VARIABLES LIKE 'datadir'\G` 查看数据库所在路径。

## 1.2 MySQL 体系结构

MySQL 数据库体系结构如图所示：
![](http://img.blog.csdn.net/20130517000945865)

MySQL 数据库区别于其他数据库的最重要的一个特点就是其插件式的表存储引擎。**注意点：存储引擎是基于表的，而不是数据库**。

## 1.3 MySQL 存储引擎

### 1.3.1 InnoDB 存储引擎

MySQL5.5.8版本开始，成为默认引擎

支持事务、行锁设计、支持外键

InnoDB 存储引擎采用聚集的方式，因此每张表的存储都是按主键的顺序进行存放。如果没有显示地在表定义时指定主键，InnoDB 存储引擎会为每一行生成一个 6 字节的 ROWID ，并以此作为主键。

### 1.3.2 MyISAM 存储引擎

不支持事务、表锁设计、支持全文搜索

### 1.3.3 NDB 存储引擎

数据全部存放在内存中

### 1.3.4 Memory 存储引擎

将表中的数据存放在内存中，如果数据重启或发生崩溃，表中的数据都将消失

### 1.3.5 Archive 存储引擎

只支持 INSERT 和 SELECT 操作，Archive 存储引擎非常适合存储归档数据

### 1.3.6 Federated 存储引擎

### 1.3.7 Maria 存储引擎

支持缓存数据和索引文件、行锁设计、提供 MVCC 功能，支持事务和非事务安全的选项、更好的 BLOB 字符类型的处理性能

### 1.3.8 其他存储引擎

## 1.4 存储引擎之间的比较

通过 `SHOW ENGINES` 查看当前使用的 MySQL数据所支持的存储引擎

各存储引擎之间比较：

![](http://img4.07net01.com/upload/images/2016/05/16/176201161020079.jpg)

## 1.5 连接 MySQL

### 1.5.1 TCP/IP

### 1.5.2 命名管道和共享内存

### 1.5.3 UNIX 域套接字

通过命令 `SHOW VARIABLES LIKE 'socket'` 进行 UNIX 域套接字文件的查找

# 第 2 章 InnoDB 存储引擎

## 2.1 InnoDB 存储引擎概述

## 2.2 InnoDB 存储引擎的版本

| 版本          | 功能                  |
| -------------- | ----------------------|
| 老版本 InnoDB  | 支持ACID、行锁设计、MVCC |
| InnoDB 1.0.x | 继承了上述版本所有功能，增加了 compress 和dynamic 页格式 |
| InnoDB 1.1.x | 继承了上述版本所有功能，增加了 Linux AIO、多回滚段 |
| InnoDB 1.2.x | 继承了上述版本所有功能，增加了全文索引支持、在线索引添加 |

## 2.3 InnoDB 体系架构

![](http://jockchou.com/blog/img/innodb-1.png)

后台线程的主要作用是负责刷新内存池的数据，保证缓冲池中的内存缓存的是最近的数据。此外将已修改的数据文件刷新到磁盘文件，同时保证在数据库发生异常的情况下 InnoDB 会恢复到正常运行状态。

### 2.3.1 后台线程

- **1.Master Thread**

将缓冲池中的数据**异步**刷新到磁盘，保证数据的一致性，包括脏页的刷新、合并插入缓冲、UNDO页的回收。

- **2.IO Thread**

处理 IO 请求
包括 write、read、insert buffer和log IO thread

- **3.Purge Thread**

回收已经使用并分配的 undo 页。1.2版本之前只支持一个 Purge Thread 线程

- **4.Page Cleaner Thread**

在 1.2.x 版本中引入，作用是讲之前版本中脏页的刷新操作都放入到单独的线程中来完成。其目的是减轻原 Master Thread 的工作及对于用户查询线程的阻塞。

### 2.3.2 内存

InnoDB 存储引擎中，缓冲页的大小默认为 16KB 。

InnoDB 1.0.x 版本开始支持压缩页功能，即将原本 16KB 的页压缩为 1KB、2KB、4KB 和 8KB。对于非 16KB 的页通过 unzip_LRU 列表进行管理。在 unzip_LRU 列表中对不同压缩页大小的页进行分别管理。

- **1.缓冲池**

在内存中开辟一块空间存放：索引页、数据页、undo 页、插入缓冲、自适应哈希索引、InnoDB 存储的锁信息、数据字典信息。

`innodb_buffer_pool_size` 设置缓冲池的大小

`innodb_buffer_pool_instances` 设置缓冲池实例的个数（1.0.x斑版本开始）

- **2.LRU List、Free List 和 Flush List**

内存管理算法

1. LRU（最近最少使用算法）

LRU List 用来管理已经读取的页。最频繁使用的页在 LRU 列表的前端，而最少使用的页在 LRU 列表的尾端。InnoDB 引擎对 LRU 算法有优化，将新读取到的页插入到列表的 midpoint 位置，而不是尾端。

`innodb_old_blocks_pct` 插入 LRU 列表的位置

`innodb_old_blocks_time` 设置页读取到 mid 位置后需要等待多久才会被加入到 LRU 列表的热端

2. Free List

Free List 存放可用的空闲页

3. Flush List

在 LRU 列表中的页被修改之后，称该页为脏页，即缓冲池中的页和磁盘上的页的数据产生了不一致。这时数据库会通过 CHECKPOINT 机制将脏页刷新回磁盘，Flush 列表中存放的即为脏页列表。

- **3. 重做日志缓冲**

InnoDB 存储引擎首先将重做日志信息放入 redo log buffer ，然后按照一定的频率将其刷新到重做日志文件。 redo log buffer 一般不需要设置很大，通过参数 `innodb_log_buffer_size` 设置，默认为 8MB。

三种情况将 redo log buffer 中的内容刷新到磁盘

1. Master Thread 每一秒将重做日志缓冲刷新到重做日志文件
2. 每个事务提交时将重做日志缓冲刷新到重做日志文件
3. 当重做日志缓冲池剩余空间小于 1/2 时，重做日志缓冲刷新到重做日志文件。

- **4.额外的内存池**

在 InnoDB 存储引擎中，对内存的管理是通过一种称为内存堆的方式进行的。在对一些数据结构本身的内存进行分配是，需要从额外的内存池中进行申请，当该区域的内存不够是，会从缓冲池中进行申请。

## 2.4 Checkpoint 技术

当前事务数据库系统普遍采用了 Write Ahead Log 策略，即当事务提交时，先写重做日志，再修改页。

Checkpoint 技术的目的：

- 缩短数据库的恢复时间
- 缓冲池不够用是，刷新脏页
- 重做日志不可用时，刷新脏页

重做日志出现不可用的情况是因为当前事务数据库系统对重做日志的设计都是循环使用的，并不是让其无线增大的。

对 InnoDB 存储引擎而言，是通过 LSN（Log Sequence Number）来标记版本的。 LSN 实际上对应日志文件的偏移量。

在 InnoDB 存储引擎内部，氛分为两种 Checkpoint，分别是：**Sharp Checkpoint**、**Fuzzy Checkpoint**。

**Sharp Checkpoint**发生在数据库关闭时将所有的脏页都刷新回磁盘，这是默认的工作方式，即参数 `innodb_fast_shutdown=1`。

**Fuzzy Checkponit**是数据库在运行过程中采用的 Checkpint 方式，其包括四种情况：

- Master Thread Checkpoint

每秒或者每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘。这个过程是异步的，即此时 InnoDB 存储引擎可以进行其他的操作，用户查询线程不会阻塞。

- FLUSH_LRU_LIST Checkpoint

为保证 LRU 列表中差不多存在 100 个空闲页可供使用
参数 `innodb_lru_scan_depth` 控制 LRU 列表中可用页的数量

- Async/Sync Flush Checkpoint

指的是重做日志文件不可用的情况，这时需要强制将一些页刷新回磁盘。

- Dirty Page too much Checkpoint

脏页的数量太多，导致 InnoDB 存储引擎强制进行 Checkpoint。其目的总的来说还是为了保证缓冲池中有足够可用的页。
参数 `innodb_max_dirty_pages_pct` 设置缓冲池中脏页的百分比，达到百分比后就进行 Checkpoint 。

## 2.5 Master Thread 工作方式

### 2.5.1 InnoDB 1.0.x 版本之前的 Master Thread

Master Thread 具有最高的线程优先级别。其内部由多个循环（loop）组成：主循环（loop）、后台循环（background loop）、刷新循环（flush loop）、暂停循环（suspend loop）。

主循环包括两大部分的操作：每秒钟的操作和每 10 秒的操作。

主循环每秒钟的操作包括：
- 日志缓冲刷新到磁盘，即使这个事务还没有提交（总是）
- 合并插入缓冲（可能）
- 至多刷新 100 个 InnoDB 的缓冲池中的脏页到磁盘（可能）
- 如果当前没有用户活动，则切换到 background loop （可能）

主循环每 10 秒的操作包括：
- 刷新 100 个脏页到磁盘（可能的情况下）
- 合并至多 5 个插入缓冲（总是）
- 将日志缓冲刷新到磁盘（总是）
- 删除无用的 Undo 页（总是）
- 刷新 100 个或者 10 个脏页到磁盘（总是）

后台循环（background loop）操作包括：
- 删除无用的 Undo 页（总是）
- 合并 20 个插入缓冲（总是）
- 跳回到主循环（总是）
- 不断刷新 100 个页知道符合条件（可能，跳转到 flush loop 中完成）

### 2.5.2 InnoDB 1.2.x 版本之前的Master Thread

从 InnoDB 1.0.x开始，提供参数 `innodb_io_capacity` ，用来表示磁盘 IO 的吞吐量，默认值200.对于刷新到磁盘也的数量，会按照 innodb_io_capacity 的百分比来进行控制。
- 在合并插入缓冲，合并插入缓冲的数量为 innodb_io_capacity 值为 5%
- 在从缓冲区刷新脏页时，刷新脏页的数量为innodb_io_capacity


InnoDB 1.0.x 版本带来的另一个参数是 `innodb_adaptive_flushing`（自适应地刷新），该值影响每秒刷新脏页的数量。原来的刷新规则是：脏页的缓冲池所占的比例小于 `innodb_max_dirty_pages_pct` 时，不刷新脏页；大于 `innodb_max_dirty_pages_pct` 时，刷新 100 个脏页。随着 `innodb_adaptive_flushing` 参数的引入，InnoDB 存储引擎会通过一个名为 `buf_flush_get_desired_flush_rate` 的函数来判断需要刷新脏页的最合适的数量。粗略地翻阅源代码后发现 `buf_flush_get_desired_flush_rate` 通过判断产生重做日志的速度来决定最合适的刷新脏页数量。因此，当脏页的比例小于　`innodb_max_dirty_pages_pct` 时，也会刷新一定量的脏页。

InnoDB 1.0.x版本引入参数 `innodb_purge_batch_size` 控制每次 flush purge 回收的 Undo 页的数量。

### 2.5.3 InnoDB 1.2.x 版本的 Master Thread

对于刷新脏页的操作，从 Master Thread 线程分离到一个单独的 Page Cleaner Thread，从而减轻了 Master Thread 的工作，同时进一步提高了系统的并发性。

## 2.6 InnoDB 关键特性

InnoDB 存储引擎的关键特性包括：
- 插入缓冲（Insert Buffer）
- 两次写（Double Write）
- 自适应哈希索引(Adaptive Hash Index)
- 异步 IO（Async IO）
- 刷新邻接页（Flush Neighbor Page）

### 2.6.1 插入缓冲

InnoDB 存储引擎开创性的设计了 Insert Buffer，对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入；若不在，则先放入到一个 Insert Buffer 对象中，好似欺骗数据库这个非聚集的索引已经插到叶子节点，而实际并没有，只是存放在另一个位置。然后再以一定频率和情况进行 Insert Buffer 和辅助索引叶子节点的 merge 操作，这时通常能将多个插入合并到一个操作中，这就大大提高了对于非聚集索引插入的性能。

Insert Buffer 使用需要满足条件:
- 索引是辅助索引
- 索引不是唯一的














































# 第3章 文件

## 3.1 参数文件

通过命名 `mysql --help | grep my.cnf` 查找 MySQL 实例读取配置文件的顺序

### 3.1.1 什么是参数

通过命令 `SHOW VARIABLES LIKE '******'` 或者通过 information_schema 架构下的 GLOBAL_VARIABLES 视图进行查看

### 3.1.2 参数类型

- 动态参数
- 静态参数

动态参数可以通过 
```
SET 
	| [global | session] system_var_name=expr
	| [@@global. | @@session. | @@] system_var_name=expr
```
设置参数。

通过
```
SELECT [@@global | @@session].system_var_name
```
查看不同作用域的参数值

对变量的全局值进行了修改，在这次的实例生命周期内都有效，但 MySQL 实例本身并不会对参数文件中的该值进行修改。

## 3.2 日志文件

- 错误日志（error log）
- 二进制日志（binlog）
- 慢查询日志（slow query log）
- 查询日志（log）

### 3.2.1 错误日志

错误日志文件对 MySQL 的启动、运行、关闭过程进行了记录。

`SHOW VARIABLES LIKE 'log_error'\G`
查看错误日志文件所在目录

### 3.2.2 满查询日志

可以在 MySQL 启动时设一个阈值，将运行时间超过该值的所有 SQL 语句都记录到慢查询日志文件中。

`SHOW VARIABLES LIKE 'long_query_time'\G`查询阈值时间

`SHOW VARIABLES LIKE 'log_slow_queries'\G`查询慢日志文件是否开启

`SHOW VARIABLES LIKE 'log_queries_not_using_indexs'\G`查询慢日志文件是否将不使用索引的 SQL 语句记录到慢查询日志文件中。

参数 log_output 指定了慢查询输出的格式，默认为 FILE，可以将它设为 TABLE。

### 3.2.3 查询日志

查询日志记录了所有对 MySQL 数据库请求的信息，无论这些请求是否得到了正确的执行。

### 3.2.4 二进制日志

二进制日志记录了对 MySQL 数据库执行更改的所有操作，但是不包括 SELECT 和 SHOW 这类操作，因为这类操作对数据本身并没有修改。然而，若操作本事并没有导致数据库发生变化，那么该操作可能也会写入二进制日志。

二进制日志文件作用：
- 恢复
- 复制
- 审计

二进制日志记录相关配置文件的参数：
- max_binlog_size 指定单个二进制日志文件的最大值，如果超过该值，则产生新的二进制日志文件
- binlog_cache_size 是基于会话的，当一个事务的记录大于设定的 binlog_cache_size 时，MySQL 会把缓冲池中的日志写入一个**临时文件**中
- sync_binlog 表示每写缓冲多少次就同步到磁盘
- binlog-do-db
- binlog-ignore-db
- log-slave-update
- binlog_format

## 3.3 套接字文件

在 UNIX 系统下本地连接 MySQL 可以采用 UNIX 域套接字方式，这种方式需要一个套接字（socket）文件。套接字文件可由参数 socket 控制。一般在 /tmp 目录下。

`SHOW VARIABLES LIKE 'socket'\G` 查看套接字文件所在目录

## 3.4 pid 文件

当 MySQL 实例启动时，会将自己的进程 ID 写入一个文件中——该文件即为 pid 文件。

`SHOW VARIABLES LIKE 'pid_file'\G`查看pid文件所在位置

## 3.5 表结构定义文件

因为 MySQL 插件式存储引擎的体系结构的关系，MySQL 数据的存储是根据表进行的每个表都会有与之对应的文件。但不论表采用何种存储引擎，MySQL 都有一个以 frm 为后缀名的文件，这个文件记录了该表的表结构定义。

## 3.6 InnoDB 存储引擎文件

### 3.6.1 表空间文件

InnoDB 采用将存储的数据按表空间进行存放的设计。在默认配置下会有一个初始大小为 10MB，名为 ibdata1 的文件。

用户可以通过多个文件组成一个表空间，同时制定文件的属性。

设置 `innodb_data_file_path` 参数后，所有基于 InnoDB 存储引擎的表的数据都会记录到该共享表空间中。

若设置了参数 `innodb_file_per_table`，则用户可以将每个基于 InnoDB 存储引擎的表产生一个独立表空间。独立表空间的命名规则为：表名.ibd。

**注意点：**这些单独的表空间文件仅存储该表的数据、索引和插入缓冲 BITMAP等信息，其余信息还是存放在默认的表空间中。

### 3.6.2 重做日志文件

在默认情况下，在 InnoDB 存储引擎的数据目录下会有两个名为 ib_logfile0 和 ib_logfile1 的文件。

每个 InnoDB 存储引擎至少有 1 个重做日志文件组，每个文件组下至少有 2 个重做日志文件，如默认的 ib_logfile0 和 ib_logfile1.

影响重做日志文件属性的参数：
- innodb_log_file_size 指定每个重做日志文件的大小
- innodb_log_files_in_group 指定日志文件组中重做日志文件的数量，默认为 2
- innodb_mirrored_log_groups 指定日志镜像文件组的数量，默认为 1，表示只有一个日志文件组，没有镜像。
- innodb_log_group_home_dir 指定了日志文件组所在路径


重做日志文件的大小设置很关键，不能太大，如果设置得很大，在恢复时可能需要很长的时间；另一方面又不能设置得太小了，否则可能导致一个事务的日志需要多次切换重做日志文件，此外，重做日志文件太小会导致频繁地发生 async checkpoint，导致性能的抖动。

二进制日志文件记录的是关于一个事务的具体操作内容，即该日志是逻辑日志。而 InnoDB 存储引擎的重做日志文件记录的是关于每个页的更改情况。

二进制日志文件仅在事务提交前进行提交，即只写磁盘一次，不论这时该事务多大。而在事务进行的过程中，却不断有重做日志条目被写入到重做日志文件中。

重做日志条目结构：

| redo_log_type | space | page_no | redo_log_body |
|---------------|-------|---------|---------------|

- redo_log_type 占用 1 字节，表示重做日志的类型
- space 表示表空间的 ID，但采用压缩的方式，因此占用的空间可能小于 4 字节
- page_no 表示页的偏移量，同样采用压缩的方式
- redo_log_body 表示每个重做日志的数据部分，恢复时需要调用相应的函数进行解析

# 第 4 章 表

## 4.1 索引组织表

InnoDB 存储引擎选择或创建主键方式：
- 首先判断表中是否有非空的唯一索引，如果有，则该列即为主键
- 如果不符合上述条件，InnoDB 存储引擎自动创建一个 6 字节大小的指针

当表中有多个非空索引的时候，选择第一个定义的非空唯一索引（**定义索引的顺序**，不是创建表时列的顺序）

`_rowid` 可以显示表的主键，但是只能用于查看单个列为主键的情况。

## 4.2 InnoDB 逻辑存储结构

InnoDB 存储引擎中，所有的数据都被逻辑的存放在一个空间中，称为表空间，表空间又由段、区、页组成。
![](http://images.cnitblog.com/blog/645933/201411/111705339758621.jpg)

### 4.2.1 表空间

### 4.2.2 段

### 4.2.3 区

区是由连续页组成的空间，在任何情况下每个区的大小都默认为 1MB。

### 4.2.4 页

`innodb_page_size` 设置页的大小：4KB、8KB、16KB

### 4.2.5 行

## 4.3 InnoDB 行记录格式

InnoDB 存储引擎提供了 Compact 和 Redundant 两种格式来存放行记录数据。

### 4.3.1 Compact 行记录格式

| 变长字段长度列表 | NULL 标志位 | 记录头信息 | 列1数据 | 列2数据| ······|
|--------------- | ---------- | --------- | ------ | ------ | ------- |

Compact 行记录格式中 NULL 除了占有 NULL 标志位，实际存储不占有任何空间。

每行数据除了用户定义的列之外，还有两个隐藏列，事务ID列和回滚指针列，分别为 6 字节和 7 字节。若 InnoDB 表没有定义主键，每行还会增加一个 6 字节的 rowid 列。

### 4.3.2 Redundant 行记录格式

| 字段长度偏移列表 | 记录头信息 | 列1数据 | 列2数据| ······|
|--------------- | ---------- | --------- | ------ | ------ |

### 4.3.3 行溢出数据

InnoDB 存储引擎可以将一条记录中的某些数据存储在真正的数据页面之外。一般认为 BLOB、LOB 这类的大对象列类型的存储会把数据存放在数据页面之外。但是，这个理解有点偏差，BLOB 可以不讲数据存放在溢出页面，而且即便是 VARCHAR 列数据类型，依然有可能被存放为行溢出数据。

### 4.3.4 Compressed 和 Dynamic 行记录格式

InnoDB 1.0.x 版本开始引入了新的文件格式，以前支持的 Compact 和 Redundant 格式称为 Antelope 文件格式，新的文件格式称为 Barracuda 文件格式。Barracuda 文件格式下拥有两种新的行记录格式： Compressed 和 Dynamic。

### 4.3.5 CHAR 的行结构存储

在 InnoDB 存储引擎内部，CHAR 类型被明确视为了变长类型，对于未能占满长度的字符还是填充 0x20。 因此可以认为子啊多字节字符集的情况下，CHAR 和 VARCHAR 的实际行存储基本是没有区别的。

## 4.4 InnoDB 数据页结构

InnoDB 数据页由以下 7 个部分组成：

- File Header（文件头）
- Page Header（页头）
- Infimun 和 Supremum Records
- User Recorder（用户记录，即行记录）
- Free Space（空闲空间）
- Page Directory（页目录）
- File Trailer（文件结尾信息）

### 4.4.1 File Header

File Header 用来记录页的一些信息头。

### 4.4.2 Page Header

Page Header 用来记录数据页的状态信息。

### 4.4.3 Infimum 和 Supremum Record

在 InnoDB 存储引擎中，每个数据页中有两个虚拟的行记录，用来限定记录的边界。

Infimum 记录的是比该页中任何主键值都要小的值。

Supremum 指比任何可能大的值还要大的值。

**这两个值在页创建时被建立，并且在任何情况下不会被删除。**

### 4.4.4 User Record 和 Free Record

User Record 即实际存储行记录的内容。

Free Record 即空闲空间，是一个链表数据结构。

### 4.4.5 Page Directory

Page Directory 中存放了记录的相对位置。

**B+ 树索引本身并不能找到具体的一条记录，能找到只是该记录所在的页。数据库把页载入到内存，然后通过 Page Directory 再进行二叉查找。只不过二叉查找的时间复杂度很低，同时在内存中的查找很快，因此通常忽略这部分查找所用的时间。**

### 4.4.6 File Trailer

File Trailer 存在的目的是为了检验页的完整性，将 File Trailer 中的某些值与 File Header 中的某些值进行比较，检查是否一致。

`innodb_checksums` 参数来开启或关闭这个页的完整性检查。

`innodb_checksum_algorithm` 参数来控制检测 checksum 函数的算法，默认为 crc32。

### 4.4.7 InnoDB 数据页结构实例分析

## 4.5 Named File Formats 机制

`innodb_file_format` 参数用来指定文件格式。

## 4.6 约束

### 4.6.1 数据完整性

数据完整性有三种形式：

- 实体完整性
- 域完整性
- 参照完整性

### 4.6.2 约束的创建和查找

约束的创建可以采用两种方式：

- 表建立时就进行约束定义
- 利用 ALTER TABLE 命令来进行创建约束

对于主键约束，其默认约束名为 PRIMARY 。而对于 Unique Key 约束而言，默认的约束名和列名一样，当然也可以人为指定 Unique Key 约束的名字。

### 4.6.3 约束和索引的区别

约束更是一个逻辑的概念，用来保证数据的完整性，而索引是一个数据结构，即有逻辑上的概念，在数据库中还代表着物理存储的方式。

### 4.6.4 对错误数据的约束

在某些默认的配置下，MySQL 数据库允许非法的或不正确的数据的插入或更新，又或者可以在数据库内部将其转化为一个合法的值。

通过参数 `sql_mode` 值的约束来检验。

### 4.6.5 ENUM 和 SET 约束

MySQL 数据库不支持传统的 CHECK 约束，但是通过 ENUM 和 SET 类型可以解决部分这样的约束需求。

### 4.6.6 触发器与约束

触发器的作用是在执行 INSERT、DELETE 和 UPDATE 命令之前或之后自动调用 SQL 命令或存储过程。

创建触发器的命令是 `CREATE TRIGGER` ，只有具有**Super** 权限的 MySQL 数据库用户才可以执行这条命令。

### 4.6.7 外键约束

一般来说，称被引用的表为父表，引用的表称为字表，外键定义时的 ON DELETE 和 ON UPDATE  表示在对父表进行 DELETE 和 UPDATE 操作时，对子表所做的操作，可定义的子表操作有：

- CASCADE

CASCADE 表示父表发生 DELETE 或 UPDATE 操作时，对相应的子表中的数据也进行 DELETE 或 UPDATE 操作。

- SET NULL

SET NULL 表示当父表发生 DELETE 或 UPDATE 操作是，相应的子表中的数据被更新为 NULL 值，但是子表中相应的列必须允许为 NULL 值。

- NO ACTION

NO ACTION 表示当父表发生 DELETE 或 UPDATE 操作时，抛出错误，不允许这类操作发生。

- RESTRICT

RESTRICT 表示当父表发生 DELETE 或 UPDATE 操作时，抛出错误，不允许这类操作发生。


如果定义外键时没有指定 ON DELETE 或 ON UPDATE ，RESTRICT 就是默认的外键设置。


## 4.7 视图

### 4.7.1 视图的作用

视图在数据库中发挥着重要的作用。视图的主要用途之一是用做一个抽象装置，特别是对于一些应用程序，程序本身不需要关心基表的结构，只需要按照视图定义来取数据或更新数据，因此，视图同时在一定程度上起到一个安全层的作用。

### 4.7.2 物化视图

MySQL 本身并不支持物化视图，但是通过触发器，可以在 MySQL 数据库中实现类似物化视图的功能。


## 4.8 分区表

### 4.8.1 分区概述

虽然分区功能不是在存储引擎层完成，但是并不是所有的存储引擎都支持分区。

MySQL 数据库支持的分区类型为水平分区——将同一表中不同行的记录分配到不同的物理文件中。

MySQL 目前并不支持**全局分区**。

MySQL 分区类型：

- RANGE 分区：行数据基于属于一个给定连续区间的列值被放入分区。

- LIST 分区：和 RANGE 分区类似，只是 LIST 分区面向的是离散的值。

- HASH 分区： 根据用户自定义的表达式的返回值来进行分区，返回值不能为负数。

- KEY 分区：根据 MySQL 数据库提供的哈希函数类进行分区。

**不论创建何种类型的分区，如果表中存在主键或唯一索引时，分区列必须是唯一索引的一个组成部分**

**唯一索引可以试允许 NULL 值的，并且分区列只要是唯一索引的一个组成部分，不需要整个唯一索引列都是分区列**

**如果创建表时没有指定主键，唯一索引，可以指定任何一个列为分区列**


### 4.8.2 分区类型

- RANGE 分区

可以通过查询 information_schema 架构下的 PARTITIONS 表来查看每个分区的具体信息。

优化器只能对 `YEAR()`、`TO_DAYS()`、`TO_SCONDS()`、`UNIX_TIMESTAMP()` 这类函数进行优化选择。

- LIST 分区

在使用 INSERT 插入多个行数据的过程中遇到分区未定义的值时，MyISAM 和 InnoDB 存储引擎的处理完全不同。MyISAM 引擎会将之前的行数据都插入，但之后的数据不会被插入。而 InnoDB 存储引擎将其视为一个事务，因此没有任何数据插入。

- HASH 分区

HASH 分区的目的是讲数据均匀的分布到预先定义的各个分区，保证各分区的数据数量大致都是一样的。


HASH 分区包括 HASH 和 LINEAR HASH 两种分区。

LINEAR HASH 分区使用一个更加复杂的算法来确定新行插入到已经分区的表中的位置。

LINEAR HASH 分区的优点在于，增加、删除、合并和拆分分区将变得更加快捷，这有利于处理含有大量数据的表。缺点在于，与使用 HASH 分区得到的数据分布相比，各个分区间数据的分布可能不大均衡。

- KEY 分区

KEY 分区和 HASH 分区相似，不同之处在于 HASH 分区使用用户定义的函数进行分区，KEY 分区使用 MySQL 数据库提供的函数进行分区。

- COLUMNS 分区

前面介绍的 RANGE、LIST、HASH 和 KEY 这四种分区中，分区的条件是：数据必须是整型，如果不是整型，那应该通过函数将其转化为整型。

MySQL5.5 版本开始支持 COLUMNS 分区，可视为 RANGE 分区和 LIST 分区的一种进化。COLUMNS 分区可以直接使用非整型的数据进行分区，分区根据类型直接比较而得，不需要转化为整型。

### 4.8.3 子分区

子分区实在爱分区的基础上再进行分区，有时也称这种分区为复合分区。MySQL 数据库允许在 RANGE 和 LIST 的分区上再进行 HASH 或 KEY 的子分区。

**注意点：**

- 每个子分区的数量必须相同
- 要在一个分区表的任何分区上使用 SUBPARTITION 来明确定义任何子分区，就必须定义所有的子分区
- 每个 SUBPARTITION 子句必须包括子分区的一个名字
- 子分区的名字必须是唯一的


### 4.8.4 分区中的 NULL 值

MySQL 数据库允许对 NULL 值做分区。

MySQL 数据库的分区总是视 NULL 值小于任何的一个非 NULL 值。

对于 RANGE 分区，如果像分区列插入了 NULL 值，则 MySQL 数据库会将该值放入最左边的分区。但是在删除最左边的分区的时候，并不会删除 NULL 值的记录。

在 LIST 分区下要使用 NULL 值，必须显示地指出哪个分区中放入 NULL 值，否则会报错。

HASH 和 KEY 分区对于 NULL 值的处理方式和 RANGE 分区、LIST 分区不一样。任何分区函数都会将含有 NULL 值的记录返回 0 。

### 4.8.5 分区和性能

### 4.8.6 在表和分区间交换数据

MySQL5.6 开始支持 ALTER TABLE···EXCHANGE PARTITION 语法。该语句允许分区或子分区中的数据移动到非分区表中。若分区表中的数据为空，则相当于将外部表中的数据导入到分区中。




# 第 5 章 索引与算法

## 5.1 InnoDB 存储引擎索引概述

InnoDB 存储引擎支持以下几种索引：

- B+ 树索引
- 全文索引
- 哈希索引

## 5.2 数据结构与算法

### 5.2.1 二分查找法

### 5.2.2 二叉查找树和平衡二叉树

二叉查找树：左子树键值都小于根节点键值，右子树键值都大于跟节点键值

平衡二叉树： AVL 树


## 5.3 B+ 树

B+ 树： 所有记录节点都是按键值的大小顺序存放在同一层的叶子节点上，有各叶子节点指针进行连接。

### 5.3.1 B+ 树的插入操作

| Leaf Page 满 | Index Page 满 | 操作 |
| ------------ | ------------- | ---- |
| No | No | 直接价格记录插入到叶子节点 |
| Yes | No | 1）拆分 Leaf Page 2）将中间节点放入到 Index Page 中 3）小于中间节点的记录放左边 4） 大于或等于中间节点的记录放右边 |
| Yes | Yes | 1）拆分 Leaf Page 2）小于中间节点的记录放左边 3）大于或等于中间节点的记录放右边 4）拆分 Index Page 5）小于中间节点的记录放左边 6）大于中间节点的记录放右边 7）中间节点放入上一层 Index Page |

### 5.3.2 B+ 树的删除操作

B+ 树使用填充因子来控制树的删除变化，50% 是填充因子可设的最小值。

| 叶子节点小于填充因子 | 中间节点小于填充因子 | 操作 |
| ----------------- | ------------------ | ---- |
| No | No | 直接将记录从叶子节点删除，如果该节点还是 Index Page 的节点，用该节点的右节点代替 |
| Yes | No | 合并叶子节点和它的兄弟节点，同时更新 Index Page |
| Yes | Yes | 1） 合并叶子节点和它的兄弟节点 2）更新 Index Page 3）合并 Index Page 和它的兄弟节点 |

## 5.4 B+ 树索引

B+ 索引在数据库中有一个特点是**高扇出性**。

### 5.4.1 聚集索引

InnoDB 存储引擎是索引组织表，即表中数据按照主键顺序存放。

聚集索引就是按照每张表的主键构造一棵 B+ 树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。聚集索引的特性决定了索引组织表中数据也是索引的一部分。

同 B+ 树数据结构一样，每个数据页都通过一个双向链表来进行链接。

每张表只能拥有一个聚集索引。

数据页上存放的是完整的每行的记录，而在非数据页的索引页中，存放的仅仅是键值及只想数据页的偏移量，而不是一个完整的行记录。

聚集索引的存储只是逻辑上的连续而不是物理上的连续。

聚集索引的另一个好处是，它对于主键的排序查找和范围查找速度非常快。叶子节点的数据就是用户所要查询的数据。如用户需要查询一张注册用户的表，查询最后注册的 10 位用户，由于 B+ 树索引是双向链表的，用户可以快速找到最后一个数据页，并取出 10 条记录。

另一个是范围查询，即如果要查找主键某一范围内的数据，通过叶子节点的**上层中间节点**就可以得到页的范围，之后直接读取数据页即可。

### 5.4.2 辅助索引

对于辅助索引（也称非聚集索引），叶子节点并不包含行记录的全部数据。叶子节点除了包含键值以外，每个叶子节点的索引行中还包含了一个书签。该书签用来告诉 InnoDB 存储引擎哪里可以找到与索引相对应的行数据。由于 InnoDB 存储引擎表时索引组织表，因此 InnoDB 存储引擎的辅助索引的书签就是相应行数据的聚集索引键。

当通过辅助索引来寻找数据时，InnoDB 存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后再通过主键索引找到一个完整的行记录。

### 5.4.3 B+ 树索引的分裂

- PAGE_LAST_INSERT
- PAGE_DIRECTION
- PAGE_N_DIRECTION

### 5.4.4 B+ 树索引的管理

#### 5.4.4.1 索引管理

命令 `SHOW INDEX` 可以查看表中索引信息

#### 5.4.4.2 Fast Index Creation

MySQL 5.5 版本之前对于索引的添加或者删除的这类 DDL 操作，过程为：

- 首先创建一张新的临时表，表结构为通过命令 ALTER TABLE 新定义的结构
- 然后把原表中数据导入到临时表
- 接着删除原表
- 最后把临时表重名为原来的表名


FIC 引入之后

- **辅助索引的创建** InnoDB 存储引擎会对创建索引的表加上一个 S 锁。在创建的过程中，不需要重建表
- **辅助索引的删除** InnoDB 存储引擎只需要更新内部视图，并将辅助索引的空间标记为可用，同时删除 MySQL 数据库内部视图上对该表的索引定义即可。

**FIC 方式只限定于辅助索引，对于主键的创建和删除同样需要重建一张表**

#### 5.4.4.3 Online Schema Change

#### 5.4.4.4 Online DDL

MySQL 5.6 版本开始支持 Online DDL，允许在**辅助索引**创建的同时，还允许其他诸如 INSERT、UPDATE、DELETE 这类 DML 操作。

Online DDL 包括：

- 辅助索引的创建与删除
- 改变自增长值
- 添加或删除外键约束
- 列的重命名

## 5.5 Cardinality 值

### 5.5.1 什么是 Cardinality

### 5.5.2 InnoDB 存储引擎的 Cardinality 统计

数据库对于 Cardnality 的统计都是通过采样的方法来完成的


InnoDB 存储引擎内部对更新 Cardnality 信息的策略为：

- 表中 1/16 的数据已经发生过变化
- stat_modified_counter > 2 000 000 000

命令 `SHOW INDEX FROM` 会触发 MySQL 数据库对 Cardnality 值的统计

## 5.6 B+ 树索引的使用

### 5.6.1 不同应用中 B+ 树索引的使用

### 5.6.2 联合索引

联合索引是指对表上的多个列进行索引、

从本质上来说，联合索引也是一棵 B+ 树，不同的是联合索引的键值的数量不是 1，而是大于等于2。

对于 (a,b) 或者 a 的查询都可以用到 (a,b) 这棵 B+ 树索引， 对于 b 的查询则用不到这棵树的索引。

### 5.6.3 覆盖索引

从辅助索引中可以查询的记录，而不需要查询聚集索引中的记录。使用覆盖索引的一个好处是辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索引，因此可以减少大量的 IO 操作。

### 5.6.4 优化器选择不使用索引的情况

在某些情况下，当执行 EXPLAIN 命令进行 SQL 语句的分析时，会发现优化器并没有选择索引去查找数据，而是通过扫描聚集索引，也就是直接进行全表的扫描来得到数据。这种情况多发生于**范围查找**、**JOIN 链接操作**等情况下。

### 5.6.5 索引提示

MySQL 数据库支持索引提示，显式地告诉优化器使用哪个索引。


### 5.6.6 Multi-Range Read 优化

MRR 优化的目的就是为了减少磁盘的随机访问，并且将随机访问转化为较为顺序的数据访问。

MRR 好处：

- MRR 使数据访问变得较为顺序，在查询辅助索引时，首先根据得到的查询结果，按照主键进行排序，并按照主键排序的顺序进行书签查找
- 减少缓冲池中页被替换的次数
- 批量处理对键值的查询操作

对于 InnoDB 和 MyISAM 存储引擎的范围查询和 JOIN 查询操作，MRR 的工作方式如下：

- 将查询得到的辅助索引键值存放于一个缓存中，这时缓存中的数据是根据辅助索引键值排序的
- 将缓存的键值根据 RowID 进行排序
- 根据 RowID 的排序顺序来访问实际的数据文件

### 5.6.7 Index Condition Pushdown (ICP) 优化


## 5.7 哈希算法

### 5.7.1 哈希表

### 5.7.2 InooDB 存储引擎中的哈希算法

### 5.7.3 自适应哈希索引

## 5.8 全文索引

### 5.8.1 概述

### 5.8.2 倒排索引

- inverted file index
- full inverted index

### 5.8.3 InnoDB 全文检索

### 5.8.4 全文检索















# 第 6 章 锁

## 6.1 什么是锁

数据库系统使用锁是为了支持对共享资源进行并发访问，提供数据的完整性和一致性。

MyISAM 引擎是表锁设计，InnoDB 是行锁设计。

## 6.2 lock 与 latch

latch 一般称为闩锁（轻量级的锁），因为其要求锁定的时间必须非常短。若持续的时间长，则应用的性能会非常差。在 InnoDB 存储引擎中，latch 又可以分为 mutex（互斥量）和 rwlock（读写锁）。其目的是用来保证并发线程操作临界值的正确性，并且通常没有死锁检测的机制。

lock 的对象是事务，用来锁定的是数据库中的对象，如表、页、行。并且一般 lock 的对象仅在事务 commit 或 rollback 后进行释放（不同事务隔离级别释放的时间可能不同）。此外，lock，正如在大多数数据库中一样，是有死锁机制的。

## 6.3 InnoDB 存储引擎中的锁

### 6.3.1 锁的类型

InnoDB 存储引擎实现了如下两种标准的行级锁：
- 共享锁（S Lock），允许事务读一行数据
- 排他锁（X Lock），允许事务删除或更新一行数据

S 锁仅与 S 锁兼容

InnoDB 还额外支出一种意向锁，意向锁是讲锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度上进行加锁。

两种意向锁类型：
- 意向共享锁（IS Lock），事务想要获得一张表中某几行的共享锁
- 意向排他锁（IX Lock），事务想要获得一张表中某几行的排他锁

### 6.3.2 一致性非锁定读（**默认读取方式**）

一致性的非锁定读是指 InnoDB 存储引擎通过行多版本控制的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行 DELETE 或 UPDATE 操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB 存储引擎会去读取行的一个快照数据

快照数据通过 undo 段来完成

READ COMMITTED 事务隔离级别下，对于快照数据，非锁定读总是读取被锁定行的最新一份快照数据。

REPEATEABLE READ（**InnoDB默认事务隔离级别**） 事务隔离级别下，对于快照书库，非锁定读总是读取事务开始时的行数据版本。

### 6.3.3 一致性锁定读

InnoDB 存储殷勤对于 SELECT 语句支持两种一致性读操作：

- SELECT···FOR UPDATE       //X LOCK
- SELECT···LOCK IN SHARE MODE       //S LOCK

### 6.3.4 自增长与锁

**InnoDB 存储引擎中，自增长值的列必须是索引，同时必须是索引的第一个列**

### 6.3.5 外键和锁

外键主要用于引用完整性的约束检查。

对于外键值的插入或更新，首先需要查询父表中的记录，即 SELECT 父表。但是对于父表的 SELECT 操作，不是使用一致性非锁定读的方式，因为这样会产生数据不一致的问题，因此这是使用的是 SELECT···LOCK IN SHARE MODE 方式，即主动对父表加一个 S 锁。如果这时父表上已经这样加了 X 锁，子表上的操作会被阻塞。


## 6.4 锁的算法

### 6.4.1 行锁的 3 种算法

- Record Lock：单个行记录上的锁
- Gap Lock：间隙锁，锁定一个范围，但不包含记录本身
- Next-Key Lock：Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身


## 6.5 锁问题

### 6.5.1 脏读

脏页指的是在缓冲池中已经被修改的页，但是还没有刷新到磁盘中，即数据库实例内存中的页和磁盘中的页的数据是不一致的，当然在刷新到磁盘之前，日志都已经被写入到了重做日志文件中，而所谓的脏数据是指事务对缓冲池中行记录的修改，并且还没有被提交。

### 6.5.2 不可重复读

不可重复读是指在一个事务内多次读取同一数据集合。在这个事务还没有结束时，另外一个事务也访问该同一数据集合，并做了一些 DML 操作。因此，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的数据可能是不一样的。这样就发生了再一个事务内两次读到的数据是不一样的情况，这种情况称为不可重复读。

不可重复读和脏读的区别是：脏读是读到未提交的数据，而不可重复读到的却是已经提交的数据，但是其违反了数据库事务一致性的要求。

### 6.5.3 丢失更新

丢失更新就是一个事务的更新操作会被另一个事务的更新操作所覆盖，从而导致数据的不一致。

但是，在当前数据库的任何隔离级别下，都不会导致数据库理论意义上的丢失更新问题。这是因为，即使是 READ UNCOMMITED 的事务隔离级别，对于行的 DML 操作，需要对行或其他粗粒度级别的对象加锁。

## 6.6 阻塞

因为不同锁之间的兼容性关系，在有些时刻一个事务中的锁需要等待另一个事务中锁释放它所占用的资源，这就是阻塞。

`innodb_lock_wait_timeout` 参数用来控制等待的时间（默认50s）

`innodb_rollback_on_timeout` 用来设定是否在等待超时时对进行中的事务进行回滚操作（默认为 OFF，代表不回滚）。

参数 `innodb_lock_wait_timeout` 是动态的。

## 6.7 死锁

### 6.7.1 死锁的概念

死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象。

解决死锁三种方案：

- 不要有等待，将任何等待都转化为回滚
- 超时，即当两个事务互相等待时，当一个等待时间超过设置的某一阈值时，其中一个事务进行回滚，另一个等待的事务就能继续进行。
- wait-for graph

### 6.7.2 死锁的概率

### 6.7.3 死锁的示例

## 6.8 锁升级

锁升级是指将当前锁的粒度降低。










# 第 9 章 性能调优

## 9.1 选择合适的 CPU

- OLAP 是 CPU 密集型操作
- OLTP 是 IO 密集型操作

在当前的 MySQL 数据库版本中，一条 SQL 查询语句只能在一个 CPU 中工作

## 9.2 内存的重要性

通常 InnoDB 存储引擎的缓冲池的命中率不应该小于 99%。

`show status like 'innodb%read%'\G`

| 参数 | 说明 |
| --- | ---|
| innodb_buffer_pool_reads | 表示从物理磁盘读取页的次数 |
| inndodb_buffer_pool_read_ahead | 预读的次数 |
| innodb_buffer_pool_read_ahead_evicted | 预读的页，但是没有被读取就从缓冲池中被替换的页的数量，一般用来判断预读的效率 |
| innodb_buffer_pool_read_requests | 从缓冲池中读取页的次数 | 
| innodb_data_read | 总共读入的字节数 | 
| innodb_data_reads | 发起读取请求的次数，每次读取可能需要读取多个页 |

缓冲池命中率 = (innodb_buffer_pool_read_requests)/(innodb_buffer_pool_read_requests + innodb_buffer_pool_read_ahead + innodb_buffer_pool_reads)

平均每次读取的字节数 = innodb_data_read / innodb_data_reads

## 9.3 硬盘对数据库性能的影响

### 9.3.1 传统机械硬盘

机械硬盘两个重要指标：

- 寻道时间
- 转速

传统机械硬盘因为读写磁头的原因，可以进行随机读写，但是，机械硬盘的访问需要耗费长时间的磁头旋转和定位来查找，因此顺序访问的速度要远高于随机访问。

### 9.3.2 固态硬盘

闪存中的数据是不可以更新的，只能通过扇区的覆盖重写，而在覆盖重写之前，需要执行非常耗时的擦除操作。擦除操作不能在所含数据的扇区上完成，而需要在删除整个被称为擦除块的基础上完成，这个擦除块的尺寸大于扇区的大小，通常为 128KB 或 256KB 。此外，每个擦除块有擦写次数的限制。

## 9.4 合理地设置RAID

### 9.4.1 RAID 类型

- RAID0 将多个磁盘合并成一个大的磁盘，不会有冗余，并行 I/O，速度最快。
- RAID1 两组以上的 N 个磁盘相互作为镜像，在一些多线程的操作系统中能有很好的读取速度，但写入速度略有降低。
- RAID5 它使用的是 Disk Striping (硬盘分区) 技术。RAID5 至少需要三个硬盘。 RAID5 不对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成 RAID5 的各个磁盘上，并且奇偶校验信息和想对应的数据分别存储于不同的磁盘上。当 RAID5 的一个磁盘数据发生损坏后，利用剩下的书库和相对应的奇偶校验信息去恢复被损坏的数据。
- RAID10 先镜像后分区数据
- RAID01 先分区数据后镜像
- RAID50 也称为镜像阵列条带，由至少六块硬盘组成。

### 9.4.2 RAID Write Back 功能

RAID Write Back 功能是指 RAID 控制器能够将写入的数据放入自身的缓存中，并把它们安排到后面再执行。

### 9.4.3 RAID 配置工具

## 9.5 操作系统的选择

## 9.6 不同文件系统对数据库性能的影响

## 9.7 选择合适基准测试工具

### 9.7.1 sysbench

测试方式：

- CPU 性能
- 磁盘 IO 性能
- 调度程序性能
- 内存分配及传输速度
- POSIX 线程性能
- 数据库 OLTP 基准测试

### 9.7.2 mysql-tpcc
































